\section{Methodology}

\subsection{Baseline}

Baseline was selected realtively low. Algorithm proposed is not from ML family.
Simple substitution algorithm finds toxic sequences in the given sentence and
replaces then with synonymous sequence.

\subsubsection{Datamining}

To build the dictionary of pairs (toxic sequence, safe alternative) we took the
dataset of toxic words. Each element of the dataset of toxic words was paired
with safe synonym generated by WordNet. Generated synonyms were filtered using
the same dataset to avoid forbidden words and cyclic toxic replacements.

\subsubsection{Replacement}

We performed regexp replacement of toxic sequences. Dataset went minimal
preprocessing. Moreover, we replaced only complete match of the sequences,
without substring match.

\subsubsection{Evaluation}

While it was proposed to results of baseline model, dropping the unchanged
sentences, further research proven that it is bad approach. Indeed, dropping
unchanged sentences, we increase the overall toxicity metrics. Moreover, we
would need to drop such sentences across all other models, which would result
in inconsistencies across the test set. As a result, metrics were further
tweaked for a proper representation of the results.

\subsection{SOTA Model}

As a main model to compare with, we will use current state-of-the-art model in
the field. The model was presented in the paper ``ParaDetox: Detoxification
with Parallel Data''. As a base model was chosen the BART.

\subsection{T5-finetuned}

As a solution for the task we propose T5 transformer fine-tuned on filtered
data. The main advantage of this pretrained T5-small model is it's
price(computational)-quality balance. Solution pipeline as follows:

\begin{enumerate}
      \item Load model checkpoint. In our case it is T5-small

      \item

            Tune the style of the model to the non-toxic. This step can be interpreted in
            multiple ways. General-purpose transformer can be used as translation model. We
            can consider it translating from english-toxic to english-non-toxic. That is
            why we also call it restyling of the model predictions.

      \item Evaluate on the test data and note the results
\end{enumerate}

\subsection{T5-finetuned\(^2\)}

After some tweaking of existing results, we came up with an updated solution.
Considering we have a \textbf{T5-finetuned} model, we can try to further
improve it's performance.

For instance, on creation of baseline model, we have derived the dataset of
toxic words with their non-toxic synonyms, alternatives. This dataset ideally
aligns with our initial dataset of paraphasing. We can concatenate these two
datasets to try to further improve the solution. Hence the name ---
\textbf{T5-finetuned\(^2\)}.

\subsubsection{Fine-tuning}

The only difference from the previous approach is that the datasets of baseline
model and ParaNMT filtered corpus were concatened before randomly batching into
fine-tuning.