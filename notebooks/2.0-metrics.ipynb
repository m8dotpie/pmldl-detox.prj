{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity: 0.9176121\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load GloVe vectors using gensim\n",
    "# Assuming you have the GloVe vectors in the \"glove.6B.100d.txt\" format\n",
    "glove_model = KeyedVectors.load_word2vec_format(\n",
    "    \"../data/external/glove.6B.100d.txt\", binary=False, no_header=True\n",
    ")\n",
    "\n",
    "\n",
    "def get_sentence_vector(sentence, model):\n",
    "    words = sentence.split()\n",
    "    # Filter out words that are not in the model's key_to_index\n",
    "    words = [word for word in words if word in model.key_to_index]\n",
    "    # If no words of the sentence are in the model's key_to_index, return a zero vector\n",
    "    if len(words) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    # Get vectors for each word and average them\n",
    "    vectors = [model[word] for word in words]\n",
    "    sentence_vector = np.mean(vectors, axis=0)\n",
    "    return sentence_vector\n",
    "\n",
    "\n",
    "def compute_semantic_similarity(sent1, sent2, model):\n",
    "    vec1 = get_sentence_vector(sent1, model)\n",
    "    vec2 = get_sentence_vector(sent2, model)\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]\n",
    "\n",
    "\n",
    "# Test\n",
    "original_sentence = \"This is an example sentence.\"\n",
    "paraphrased_sentence = \"This sentence is an example.\"\n",
    "\n",
    "similarity = compute_semantic_similarity(\n",
    "    original_sentence, paraphrased_sentence, glove_model\n",
    ")\n",
    "print(\"Semantic Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator network (deprecated, not used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "\n",
    "# 1. Load the dataset\n",
    "# Assuming you have a dataset in the following format:\n",
    "# original_text, paraphrased_text, label (1 for human, 0 for machine)\n",
    "data = pd.read_csv(\"labeled_dataset.csv\")\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def encode_sentences(original, paraphrase):\n",
    "    return tokenizer(\n",
    "        original,\n",
    "        paraphrase,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "\n",
    "dataset = data.apply(\n",
    "    lambda x: encode_sentences(x[\"original_text\"], x[\"paraphrased_text\"]), axis=1\n",
    ")\n",
    "\n",
    "# Convert labels to tensors\n",
    "labels = torch.tensor(data[\"label\"].values)\n",
    "\n",
    "# 2. Fine-tune BERT\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    compute_metrics=lambda preds, labels: {\n",
    "        \"accuracy\": (preds[1].argmax(-1) == labels).float().mean().item()\n",
    "    },\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# 3. Discriminator Score\n",
    "def discriminator_score(original, paraphrased):\n",
    "    inputs = encode_sentences(original, paraphrased)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Get the probability of label=1 (human-written)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        return probs[0][1].item()\n",
    "\n",
    "\n",
    "# Test\n",
    "original_sentence = \"Your example original sentence here.\"\n",
    "paraphrased_sentence = \"Your example paraphrased sentence here.\"\n",
    "\n",
    "score = discriminator_score(original_sentence, paraphrased_sentence)\n",
    "print(\"Discriminator Score:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.27799668259661947\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(sentence):\n",
    "    return word_tokenize(sentence)\n",
    "\n",
    "\n",
    "def compute_bleu_score(reference, hypothesis):\n",
    "    # Tokenize the sentences\n",
    "    reference_tokens = [tokenize(reference)]\n",
    "    hypothesis_tokens = tokenize(hypothesis)\n",
    "\n",
    "    # Use smoothing function\n",
    "    smoothie = SmoothingFunction().method4\n",
    "\n",
    "    return sentence_bleu(\n",
    "        reference_tokens, hypothesis_tokens, smoothing_function=smoothie\n",
    "    )\n",
    "\n",
    "\n",
    "# Test\n",
    "original_sentence = \"This is an example sentence.\"\n",
    "paraphrased_sentence = \"This sentence is an example.\"\n",
    "\n",
    "bleu_score = compute_bleu_score(original_sentence, paraphrased_sentence)\n",
    "print(\"BLEU Score:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METEOR Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.8518518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure you've downloaded the Punkt tokenizer models\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "def compute_meteor_score(reference, hypothesis):\n",
    "    # Tokenize the sentences\n",
    "    reference_tokens = word_tokenize(reference)\n",
    "    hypothesis_tokens = word_tokenize(hypothesis)\n",
    "\n",
    "    # The METEOR function in nltk expects the reference as a string and the hypothesis as a list of tokens\n",
    "    return single_meteor_score(reference_tokens, hypothesis_tokens)\n",
    "\n",
    "\n",
    "# Test\n",
    "original_sentence = \"This is an example sentence.\"\n",
    "paraphrased_sentence = \"This sentence is an example.\"\n",
    "\n",
    "meteor_score = compute_meteor_score(original_sentence, paraphrased_sentence)\n",
    "print(\"METEOR Score:\", meteor_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toxicity': 0.9977558, 'severe_toxicity': 0.45780033, 'obscene': 0.9929531, 'threat': 0.0037068268, 'insult': 0.953166, 'identity_attack': 0.015627943}\n"
     ]
    }
   ],
   "source": [
    "from detoxify import Detoxify\n",
    "\n",
    "# each model takes in either a string or a list of strings\n",
    "\n",
    "results = Detoxify(\"original\").predict(\"fuck you\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
