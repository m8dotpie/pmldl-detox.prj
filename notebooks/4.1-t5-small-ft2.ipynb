{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:01.766013Z",
          "iopub.status.busy": "2023-09-24T15:10:01.765366Z",
          "iopub.status.idle": "2023-09-24T15:10:01.772400Z",
          "shell.execute_reply": "2023-09-24T15:10:01.771384Z",
          "shell.execute_reply.started": "2023-09-24T15:10:01.765977Z"
        },
        "id": "B1B3qWjJfAuY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Necessary inputs\n",
        "import warnings\n",
        "\n",
        "from datasets import load_dataset, load_metric, concatenate_datasets\n",
        "import transformers\n",
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:01.774778Z",
          "iopub.status.busy": "2023-09-24T15:10:01.773897Z",
          "iopub.status.idle": "2023-09-24T15:10:01.784448Z",
          "shell.execute_reply": "2023-09-24T15:10:01.783216Z",
          "shell.execute_reply.started": "2023-09-24T15:10:01.774744Z"
        },
        "id": "r1j_cm3tfAuZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# selecting model checkpoint\n",
        "model_checkpoint = \"t5-small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:01.787917Z",
          "iopub.status.busy": "2023-09-24T15:10:01.787594Z",
          "iopub.status.idle": "2023-09-24T15:10:03.219266Z",
          "shell.execute_reply": "2023-09-24T15:10:03.218277Z",
          "shell.execute_reply.started": "2023-09-24T15:10:01.787893Z"
        },
        "id": "IreSlFmlIrIm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "transformers.set_seed(42)\n",
        "\n",
        "raw_datasets = load_dataset(\"../data/interim/dataset\")\n",
        "metric = load_metric(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6AF1xMAnKel"
      },
      "outputs": [],
      "source": [
        "synonym_dataset = load_dataset(\"synonyms\")  # add synonyms dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVe1ZWtOnpu_"
      },
      "outputs": [],
      "source": [
        "merged_train_dataset = concatenate_datasets(\n",
        "    [raw_datasets[\"train\"], synonym_dataset[\"train\"]]\n",
        ")\n",
        "merged_val_dataset = concatenate_datasets(\n",
        "    [raw_datasets[\"validation\"], synonym_dataset[\"validation\"]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:03.310034Z",
          "iopub.status.busy": "2023-09-24T15:10:03.309664Z",
          "iopub.status.idle": "2023-09-24T15:10:03.505289Z",
          "shell.execute_reply": "2023-09-24T15:10:03.504208Z",
          "shell.execute_reply.started": "2023-09-24T15:10:03.310001Z"
        },
        "id": "eXNLu_-nIrJI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# we will use autotokenizer for this purpose\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:03.533132Z",
          "iopub.status.busy": "2023-09-24T15:10:03.532860Z",
          "iopub.status.idle": "2023-09-24T15:10:03.539292Z",
          "shell.execute_reply": "2023-09-24T15:10:03.538145Z",
          "shell.execute_reply.started": "2023-09-24T15:10:03.533109Z"
        },
        "id": "-oB_72WafAue",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# prefix for model input\n",
        "prefix = \"make sentence non-toxic:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:03.541473Z",
          "iopub.status.busy": "2023-09-24T15:10:03.540621Z",
          "iopub.status.idle": "2023-09-24T15:10:03.549770Z",
          "shell.execute_reply": "2023-09-24T15:10:03.548874Z",
          "shell.execute_reply.started": "2023-09-24T15:10:03.541440Z"
        },
        "id": "vc0BSBLIIrJQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max_input_length = 256\n",
        "max_target_length = 256\n",
        "toxic = \"source\"\n",
        "non_toxic = \"target\"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + ex if ex else \" \" for ex in examples[toxic]]\n",
        "    targets = [ex if ex else \" \" for ex in examples[non_toxic]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JANClGPsjqSH"
      },
      "outputs": [],
      "source": [
        "tokenized_train = merged_train_dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gA7GyXooR9c"
      },
      "outputs": [],
      "source": [
        "tokenized_validation = merged_val_dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "# Fine-tuning the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:03.605060Z",
          "iopub.status.busy": "2023-09-24T15:10:03.604730Z",
          "iopub.status.idle": "2023-09-24T15:10:04.671893Z",
          "shell.execute_reply": "2023-09-24T15:10:04.670859Z",
          "shell.execute_reply.started": "2023-09-24T15:10:03.605029Z"
        },
        "id": "TlqNaB8jIrJW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        ")\n",
        "\n",
        "# create a model for the pretrained model\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:04.674163Z",
          "iopub.status.busy": "2023-09-24T15:10:04.673474Z",
          "iopub.status.idle": "2023-09-24T15:10:04.681771Z",
          "shell.execute_reply": "2023-09-24T15:10:04.680562Z",
          "shell.execute_reply.started": "2023-09-24T15:10:04.674126Z"
        },
        "id": "Bliy8zgjIrJY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# defining the parameters for training\n",
        "batch_size = 32\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-detoxify\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"tensorboard\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:04.684376Z",
          "iopub.status.busy": "2023-09-24T15:10:04.683883Z",
          "iopub.status.idle": "2023-09-24T15:10:04.693774Z",
          "shell.execute_reply": "2023-09-24T15:10:04.692863Z",
          "shell.execute_reply.started": "2023-09-24T15:10:04.684341Z"
        },
        "id": "eZmPm99MfAuh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:04.695838Z",
          "iopub.status.busy": "2023-09-24T15:10:04.695457Z",
          "iopub.status.idle": "2023-09-24T15:10:04.707222Z",
          "shell.execute_reply": "2023-09-24T15:10:04.706315Z",
          "shell.execute_reply.started": "2023-09-24T15:10:04.695806Z"
        },
        "id": "UmvbnJ9JIrJd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# simple postprocessing for text\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "# compute metrics function to pass to trainer\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:04.709249Z",
          "iopub.status.busy": "2023-09-24T15:10:04.708526Z",
          "iopub.status.idle": "2023-09-24T15:10:04.806768Z",
          "shell.execute_reply": "2023-09-24T15:10:04.805816Z",
          "shell.execute_reply.started": "2023-09-24T15:10:04.709216Z"
        },
        "id": "imY1oC3SIrJf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# instead of writing train loop we will use Seq2SeqTrainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_validation,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "execution": {
          "iopub.execute_input": "2023-09-24T15:10:04.808506Z",
          "iopub.status.busy": "2023-09-24T15:10:04.808050Z",
          "iopub.status.idle": "2023-09-24T15:18:44.110261Z",
          "shell.execute_reply": "2023-09-24T15:18:44.109150Z",
          "shell.execute_reply.started": "2023-09-24T15:10:04.808459Z"
        },
        "id": "uNx5pyRlIrJh",
        "outputId": "5b2f339a-dd41-45b2-8098-aff515b4fcf7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2960' max='2960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2960/2960 07:22, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.485242</td>\n",
              "      <td>21.893300</td>\n",
              "      <td>10.712900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.665900</td>\n",
              "      <td>2.382524</td>\n",
              "      <td>23.374400</td>\n",
              "      <td>10.958900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.665900</td>\n",
              "      <td>2.337265</td>\n",
              "      <td>23.603600</td>\n",
              "      <td>10.979400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.337600</td>\n",
              "      <td>2.312074</td>\n",
              "      <td>23.901100</td>\n",
              "      <td>11.028600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.337600</td>\n",
              "      <td>2.292755</td>\n",
              "      <td>23.842000</td>\n",
              "      <td>11.062600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.259800</td>\n",
              "      <td>2.283076</td>\n",
              "      <td>23.971400</td>\n",
              "      <td>11.052800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.228900</td>\n",
              "      <td>2.275079</td>\n",
              "      <td>23.886800</td>\n",
              "      <td>11.025900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.228900</td>\n",
              "      <td>2.269132</td>\n",
              "      <td>23.873400</td>\n",
              "      <td>11.020600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.188100</td>\n",
              "      <td>2.265964</td>\n",
              "      <td>23.872800</td>\n",
              "      <td>11.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.188100</td>\n",
              "      <td>2.265641</td>\n",
              "      <td>23.872000</td>\n",
              "      <td>11.018800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2960, training_loss=2.3142215007060285, metrics={'train_runtime': 446.5402, 'train_samples_per_second': 212.12, 'train_steps_per_second': 6.629, 'total_flos': 1106994429689856.0, 'train_loss': 2.3142215007060285, 'epoch': 10.0})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:19:29.403450Z",
          "iopub.status.busy": "2023-09-24T15:19:29.403061Z",
          "iopub.status.idle": "2023-09-24T15:19:30.003295Z",
          "shell.execute_reply": "2023-09-24T15:19:30.002182Z",
          "shell.execute_reply.started": "2023-09-24T15:19:29.403420Z"
        },
        "id": "YqwC0q1ofAuj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# saving model\n",
        "trainer.save_model(\"../models/t5-small-ft2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T15:19:30.753608Z",
          "iopub.status.busy": "2023-09-24T15:19:30.753167Z",
          "iopub.status.idle": "2023-09-24T15:19:31.676057Z",
          "shell.execute_reply": "2023-09-24T15:19:31.675005Z",
          "shell.execute_reply.started": "2023-09-24T15:19:30.753575Z"
        },
        "id": "ESCDDiCVfAuj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# loading the model and run inference for it\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"../models/t5-small-ft2\")\n",
        "model.eval()\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu_gsuhBp68A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTzbKy3josVg"
      },
      "outputs": [],
      "source": [
        "def test(model, tokenizer=tokenizer, batch_size=100):\n",
        "    res = pd.DataFrame({\"source\": raw_datasets[\"test\"][toxic]})\n",
        "    model_res = []\n",
        "    test_data = raw_datasets[\"test\"]\n",
        "\n",
        "    for i in tqdm(range(0, len(test_data), batch_size)):\n",
        "        batch = test_data[i : i + batch_size]\n",
        "        input_texts = [prefix + line for line in batch[toxic]]\n",
        "\n",
        "        input_ids = tokenizer(\n",
        "            input_texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "        ).input_ids\n",
        "        outputs = model.generate(input_ids=input_ids)\n",
        "\n",
        "        decoded_outputs = [\n",
        "            tokenizer.decode(output, skip_special_tokens=True) for output in outputs\n",
        "        ]\n",
        "        model_res.extend(decoded_outputs)\n",
        "\n",
        "    res[\"target\"] = model_res\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "xCpy3JHloVqj",
        "outputId": "00538a9b-ca0d-4845-923b-9d22020b673e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [04:21<00:00,  8.72s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ac7a9f7-3ece-4051-871c-88e8cda9829e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and you think grandpa is gonna protect us from...</td>\n",
              "      <td>and you think grandpa is gonna protect us from...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>might i add very clever assholes</td>\n",
              "      <td>i m sure i m going to add some clever tricks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i hate dickheads</td>\n",
              "      <td>i hate dickheads</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jason put down that stupid camera and come hel...</td>\n",
              "      <td>jason put down that camera and come help me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what a scumbag</td>\n",
              "      <td>what a scumbag</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ac7a9f7-3ece-4051-871c-88e8cda9829e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ac7a9f7-3ece-4051-871c-88e8cda9829e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ac7a9f7-3ece-4051-871c-88e8cda9829e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7c10045-6c66-41d6-9cb8-cd1c2130a37a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7c10045-6c66-41d6-9cb8-cd1c2130a37a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7c10045-6c66-41d6-9cb8-cd1c2130a37a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              source  \\\n",
              "0  and you think grandpa is gonna protect us from...   \n",
              "1                   might i add very clever assholes   \n",
              "2                                   i hate dickheads   \n",
              "3  jason put down that stupid camera and come hel...   \n",
              "4                                     what a scumbag   \n",
              "\n",
              "                                              target  \n",
              "0  and you think grandpa is gonna protect us from...  \n",
              "1       i m sure i m going to add some clever tricks  \n",
              "2                                   i hate dickheads  \n",
              "3        jason put down that camera and come help me  \n",
              "4                                     what a scumbag  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = test(model, tokenizer)\n",
        "res.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWz7k-8iwLHY"
      },
      "outputs": [],
      "source": [
        "res.to_csv(\"t5-ft2-detoxify.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
